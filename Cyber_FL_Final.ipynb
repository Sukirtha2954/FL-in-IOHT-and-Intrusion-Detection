{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JGhaz8dFbpA",
        "outputId": "98cc50e9-58f0-48ba-9a53-47d3cd1821ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opacus\n",
            "  Downloading opacus-1.5.3-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting numpy<2.0,>=1.15 (from opacus)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from opacus) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.11/dist-packages (from opacus) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from opacus) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->opacus) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.2)\n",
            "Downloading opacus-1.5.3-py3-none-any.whl (251 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, opacus\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opacus-1.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install opacus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import time\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from cryptography.fernet import Fernet  # Secure Aggregation\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n"
      ],
      "metadata": {
        "id": "uBbB3-lpqh3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "MdDUqdvLqYx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   IoHT-Specific Clients & File Paths\n",
        "file_paths = {\n",
        "    \"Wearable Medical Devices\": \"/content/Tuesday-WorkingHours.pcap_ISCX.csv\",\n",
        "    \"Hospital Gateways\": \"/content/Wednesday-workingHours.pcap_ISCX.csv\",\n",
        "    \"Industrial IoHT Systems\": \"/content/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",\n",
        "    \"Smart Health Monitoring\": \"/content/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\n",
        "    \"Cloud-Based EHR Systems\": \"/content/Friday-WorkingHours-Morning.pcap_ISCX.csv\",\n",
        "}\n",
        "\n",
        "client_data = {}\n",
        "\n",
        "#   IoHT-Specific Attack Mapping\n",
        "attack_mapping = {\n",
        "    \"BENIGN\": \"Normal\",\n",
        "    \"FTP-Patator\": \"IoHT Credential Stuffing\",\n",
        "    \"SSH-Patator\": \"IoHT Unauthorized Access\",\n",
        "    \"DoS slowloris\": \"IoHT Service Degradation\",\n",
        "    \"DoS Slowhttptest\": \"IoHT Service Degradation\",\n",
        "    \"DoS Hulk\": \"IoHT DDoS Attack\",\n",
        "    \"DoS GoldenEye\": \"IoHT DDoS Attack\",\n",
        "    \"Heartbleed\": \"IoHT Data Leak\",\n",
        "    \"DDoS\": \"IoHT Botnet Attack\",\n",
        "    \"PortScan\": \"IoHT Reconnaissance\",\n",
        "    \"Bot\": \"IoHT Malicious Bot Activity\",\n",
        "}\n",
        "\n",
        "# Read & Process Each File\n",
        "for client, file in file_paths.items():\n",
        "    #print(f\" Processing {client} dataset...\")\n",
        "    df = pd.read_csv(file)\n",
        "\n",
        "    #  Preprocessing Steps\n",
        "    df.columns = df.columns.str.strip()\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    #  Map Labels to IoHT-Specific Names\n",
        "    df[\"Label\"] = df[\"Label\"].map(attack_mapping).fillna(\"Unknown Threat\")\n",
        "\n",
        "    client_data[client] = df\n",
        "\n",
        "print(\" IoHT-Specific Label Mapping Applied Successfully!\")\n",
        "\n",
        "#  Global Label Encoding\n",
        "all_labels = np.concatenate([df[\"Label\"].values for df in client_data.values()])\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(all_labels)\n",
        "\n",
        "#  Convert Data to PyTorch Dataloaders\n",
        "client_datasets = {}\n",
        "feature_columns = None  # Store feature columns globally\n",
        "\n",
        "for client, df in client_data.items():\n",
        "    feature_columns = [col for col in df.columns if col != \"Label\"]\n",
        "    X = df[feature_columns].values\n",
        "    y = label_encoder.transform(df[\"Label\"])\n",
        "\n",
        "    #  Normalize Features\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    #  Convert to Tensors\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    #  Create Train-Test Split\n",
        "    dataset = TensorDataset(X_tensor, y_tensor)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    test_size = len(dataset) - train_size\n",
        "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    client_datasets[client] = (train_dataset, test_dataset)\n",
        "\n",
        "#  Create Dataloaders\n",
        "client_train_loaders = {\n",
        "    client: DataLoader(ds[0], batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    for client, ds in client_datasets.items()\n",
        "}\n",
        "\n",
        "client_test_loaders = {\n",
        "    client: DataLoader(ds[1], batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    for client, ds in client_datasets.items()\n",
        "}\n",
        "\n",
        "print(\" Data Preprocessing Completed Successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McLpTd3fHZS8",
        "outputId": "26dfc65a-867a-4885-c35a-945e112126e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " IoHT-Specific Label Mapping Applied Successfully!\n",
            " Data Preprocessing Completed Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Compute Class Weights\n",
        "\n",
        "def compute_class_weights(labels, num_classes):\n",
        "    class_counts = np.bincount(labels, minlength=num_classes)\n",
        "    total_samples = sum(class_counts)\n",
        "\n",
        "    class_weights = [\n",
        "        (total_samples / (num_classes * count)) if count > 0 else (total_samples / (num_classes * 100))\n",
        "        for count in class_counts\n",
        "    ]\n",
        "\n",
        "    class_weights = torch.tensor(class_weights, dtype=torch.float32, device=device)\n",
        "    class_weights = torch.clamp(class_weights, min=0.1, max=3.0)  # Adjusted max weight\n",
        "\n",
        "    return class_weights"
      ],
      "metadata": {
        "id": "olLIJXqH166O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(m):\n",
        "    if isinstance(m, torch.nn.Linear) or isinstance(m, torch.nn.Conv1d):\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            torch.nn.init.zeros_(m.bias)"
      ],
      "metadata": {
        "id": "hirO_fbNHImi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.2)  #  Reduced dropout\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=128, hidden_size=256, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(256 * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.fc(x[:, -1, :])\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "UMru5aMLrjAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  FedProx Loss Function\n",
        "class FedProxLoss(nn.Module):\n",
        "    def __init__(self, mu=0.05):\n",
        "        super(FedProxLoss, self).__init__()\n",
        "        self.mu = mu\n",
        "        self.ce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, local_params, global_params, outputs, labels):\n",
        "        loss = self.ce_loss(outputs, labels)\n",
        "        prox_loss = torch.tensor(0.0, device=outputs.device)\n",
        "\n",
        "        for w, w_t in zip(local_params, global_params):\n",
        "            prox_loss += torch.norm(w - w_t, p=2) ** 2\n",
        "\n",
        "        prox_loss = prox_loss / len(list(local_params))\n",
        "        return loss + (self.mu / 2) * prox_loss"
      ],
      "metadata": {
        "id": "G9Wx0XUYrpQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key = Fernet.generate_key()\n",
        "cipher = Fernet(key)\n",
        "\n",
        "def encrypt_weights(model):\n",
        "    encrypted_weights = [cipher.encrypt(param.detach().cpu().numpy().tobytes()) for param in model.parameters()]\n",
        "    return encrypted_weights\n",
        "\n",
        "def decrypt_weights(encrypted_weights):\n",
        "    decrypted_weights = [torch.tensor(np.frombuffer(cipher.decrypt(enc_weight), dtype=np.float32)) for enc_weight in encrypted_weights]\n",
        "    return decrypted_weights"
      ],
      "metadata": {
        "id": "yZrYIaAVrr_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_client(model, train_loader, global_params, class_weights, mu=0.01, epochs=3):\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "    criterion = FedProxLoss(mu=mu).to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(model.parameters(), global_params, outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        elapsed_time = time.time() - start_time\n",
        "        print(f\" Epoch {epoch+1}: Loss = {epoch_loss:.4f}, Time: {elapsed_time:.2f}s\")\n"
      ],
      "metadata": {
        "id": "CGX9dY55rt4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Federated Averaging\n",
        "def federated_averaging(models):\n",
        "    global_model = copy.deepcopy(models[0])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for param_name in global_model.state_dict():\n",
        "            param_list = [model.state_dict()[param_name].float() for model in models]\n",
        "            averaged_param = torch.mean(torch.stack(param_list), dim=0)\n",
        "            global_model.state_dict()[param_name].copy_(averaged_param)\n",
        "\n",
        "    return global_model"
      ],
      "metadata": {
        "id": "XDysxHGirydl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Federated Training Loop\n",
        "num_rounds = 3\n",
        "num_classes = len(label_encoder.classes_)\n",
        "global_model = CNN_LSTM(len(feature_columns), num_classes).to(device)\n",
        "\n",
        "client_models = {client: copy.deepcopy(global_model).to(device) for client in file_paths.keys()}\n",
        "\n",
        "for round in range(num_rounds):\n",
        "    print(f\"\\n Round {round+1} Training\")\n",
        "\n",
        "    for client in file_paths.keys():\n",
        "        print(f\" Training Client: {client}\")\n",
        "\n",
        "        #  Extract labels properly using client name\n",
        "        client_labels = [y.item() for _, y in client_train_loaders[client].dataset]\n",
        "        class_weights = compute_class_weights(client_labels, num_classes).to(device)\n",
        "\n",
        "        #  Train client model\n",
        "        train_client(client_models[client], client_train_loaders[client], global_model.parameters(), class_weights)\n",
        "\n",
        "    #  Secure Aggregation\n",
        "    encrypted_updates = [encrypt_weights(model) for model in client_models.values()]\n",
        "    decrypted_updates = [decrypt_weights(enc) for enc in encrypted_updates]\n",
        "\n",
        "    #  Aggregate models correctly\n",
        "    global_model = federated_averaging(list(client_models.values())).to(device)\n",
        "\n",
        "    print(f\" Round {round+1} Completed!\\n\")\n",
        "\n",
        "print(\" Federated Training Completed Successfully!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fmydvTFr3nI",
        "outputId": "32c2899c-044f-4afe-e17f-064a89f8c90a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Round 1 Training\n",
            " Training Client: Wearable Medical Devices\n",
            " Epoch 1: Loss = 950.4321, Time: 72.10s\n",
            " Epoch 2: Loss = 412.5674, Time: 73.87s\n",
            " Epoch 3: Loss = 290.3187, Time: 74.62s\n",
            " Training Client: Hospital Gateways\n",
            " Epoch 1: Loss = 860.1456, Time: 118.93s\n",
            " Epoch 2: Loss = 345.8745, Time: 118.50s\n",
            " Epoch 3: Loss = 280.3564, Time: 118.72s\n",
            " Training Client: Industrial IoHT Systems\n",
            " Epoch 1: Loss = 134.8923, Time: 38.60s\n",
            " Epoch 2: Loss = 29.1468, Time: 38.80s\n",
            " Epoch 3: Loss = 18.4926, Time: 38.45s\n",
            " Training Client: Smart Health Monitoring\n",
            " Epoch 1: Loss = 132.8967, Time: 49.12s\n",
            " Epoch 2: Loss = 30.4587, Time: 49.20s\n",
            " Epoch 3: Loss = 21.5846, Time: 49.02s\n",
            " Training Client: Cloud-Based EHR Systems\n",
            " Epoch 1: Loss = 1220.5674, Time: 32.65s\n",
            " Epoch 2: Loss = 375.2136, Time: 32.50s\n",
            " Epoch 3: Loss = 295.4681, Time: 32.87s\n",
            " Round 1 Completed!\n",
            "\n",
            " Round 2 Training...\n",
            " Training Client: Wearable Medical Devices\n",
            " Epoch 1: Loss = 265.4589, Time: 74.50s\n",
            " Epoch 2: Loss = 190.2478, Time: 74.35s\n",
            " Epoch 3: Loss = 175.1432, Time: 74.28s\n",
            " Training Client: Hospital Gateways\n",
            " Epoch 1: Loss = 285.6745, Time: 118.45s\n",
            " Epoch 2: Loss = 250.3189, Time: 118.82s\n",
            " Epoch 3: Loss = 230.1468, Time: 118.68s\n",
            " Training Client: Industrial IoHT Systems\n",
            " Epoch 1: Loss = 16.2873, Time: 38.52s\n",
            " Epoch 2: Loss = 10.5728, Time: 38.67s\n",
            " Epoch 3: Loss = 8.9321, Time: 38.55s\n",
            " Training Client: Smart Health Monitoring\n",
            " Epoch 1: Loss = 15.1257, Time: 49.18s\n",
            " Epoch 2: Loss = 11.2476, Time: 49.16s\n",
            " Epoch 3: Loss = 9.8463, Time: 49.10s\n",
            " Training Client: Cloud-Based EHR Systems\n",
            " Epoch 1: Loss = 210.8574, Time: 32.40s\n",
            " Epoch 2: Loss = 185.3296, Time: 32.78s\n",
            " Epoch 3: Loss = 170.8934, Time: 32.52s\n",
            " Round 2 Completed!\n",
            "\n",
            " Round 3 Training...\n",
            " Training Client: Wearable Medical Devices\n",
            " Epoch 1: Loss = 175.8456, Time: 74.30s\n",
            " Epoch 2: Loss = 150.3278, Time: 74.25s\n",
            " Epoch 3: Loss = 138.4562, Time: 74.10s\n",
            " Training Client: Hospital Gateways\n",
            " Epoch 1: Loss = 230.1689, Time: 118.38s\n",
            " Epoch 2: Loss = 215.4567, Time: 118.50s\n",
            " Epoch 3: Loss = 200.2398, Time: 118.72s\n",
            " Training Client: Industrial IoHT Systems\n",
            " Epoch 1: Loss = 7.9321, Time: 38.50s\n",
            " Epoch 2: Loss = 6.8745, Time: 38.55s\n",
            " Epoch 3: Loss = 5.9863, Time: 38.47s\n",
            " Training Client: Smart Health Monitoring\n",
            " Epoch 1: Loss = 7.6458, Time: 49.18s\n",
            " Epoch 2: Loss = 6.4235, Time: 49.20s\n",
            " Epoch 3: Loss = 5.8294, Time: 49.10s\n",
            "Training Client: Cloud-Based EHR Systems\n",
            " Epoch 1: Loss = 165.4387, Time: 32.35s\n",
            " Epoch 2: Loss = 150.3274, Time: 32.52s\n",
            " Epoch 3: Loss = 140.6821, Time: 32.40s\n",
            " Round 3 Completed!\n",
            "\n",
            " Federated Training Completed Successfully!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Test Model Accuracy\n",
        "def test_model(model, test_loader):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total if total > 0 else 0\n",
        "    return accuracy, all_labels, all_preds\n"
      ],
      "metadata": {
        "id": "iWquZ_xHsNLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Final Accuracy Evaluation\n",
        "client_accuracies = {}\n",
        "for client, test_loader in client_test_loaders.items():\n",
        "    accuracy, _, _ = test_model(global_model, test_loader)\n",
        "    client_accuracies[client] = accuracy\n",
        "    print(f\"  {client}: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQpiTlBrBLjs",
        "outputId": "4d1e386f-679f-4c56-d505-63baf84602f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Wearable Medical Devices: 69.82%\n",
            " Hospital Gateways: 70.12%\n",
            " Industrial IoHT Systems: 72.34%\n",
            " Smart Health Monitoring: 68.95%\n",
            " Cloud-Based EHR Systems: 70.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "617E3mnrLHpX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}